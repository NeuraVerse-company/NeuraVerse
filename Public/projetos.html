<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interface de IA</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background: #000000;
            overflow: hidden;
            position: relative;
        }
        #main-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            z-index: 1;
        }
        #neural-network {
            width: 200px;
            height: 100px;
            background: transparent;
        }
        #avatar-container {
            display: flex;
            flex-direction: row;
            gap: 50px;
        }
        .avatar {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            background-color: #343541;
            border: 3px solid #0078d4;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            position: relative;
        }
        .avatar img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #mic-button {
            padding: 10px;
            background-color: #0078d4;
            color: white;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            font-size: 16px;
            width: 40px;
            height: 40px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #mic-button.listening {
            background-color: #ff4444;
        }
        #mic-reminder {
            color: #ff4444;
            font-size: 14px;
            text-align: center;
            display: none; /* Escondido por padrÃ£o */
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div id="main-container">
        <canvas id="neural-network"></canvas>
        <div id="avatar-container">
            <div class="avatar" id="ai-avatar">
                <img src="https://via.placeholder.com/100?text=IA" alt="Modelo de IA">
            </div>
            <div class="avatar" id="user-avatar">
                <img src="https://via.placeholder.com/100?text=UsuÃ¡rio" alt="UsuÃ¡rio">
            </div>
        </div>
        <button id="mic-button">ðŸŽ¤</button>
        <div id="mic-reminder">Por favor, ative o microfone para usar esta pÃ¡gina.</div>
    </div>

    <script src="https://aka.ms/csspeech/jsbrowserpackage"></script>
    <script>
        const { SpeechConfig, AudioConfig, SpeechRecognizer } = window.SpeechSDK;

        // ConfiguraÃ§Ãµes do Azure Speech Service
        const subscriptionKey = "SUA_CHAVE_DO_AZURE_SPEECH"; // Substitua pela sua chave
        const region = "SUA_REGIAO"; // Exemplo: "eastus"
        const speechConfig = SpeechConfig.fromSubscription(subscriptionKey, region);
        speechConfig.speechRecognitionLanguage = "pt-BR";

        // Elementos da interface
        const micButton = document.getElementById("mic-button");
        const micReminder = document.getElementById("mic-reminder");
        let recognizer = null;
        let isProcessing = false;

        // Configurar o canvas
        const canvas = document.getElementById("neural-network");
        canvas.width = 200;
        canvas.height = 100;
        const ctx = canvas.getContext("2d");

        // NÃ³s do triÃ¢ngulo
        const nodes = [
            { x: 100, y: 30, color: "#1E90FF" },
            { x: 80, y: 60, color: "#00BFFF" },
            { x: 120, y: 60, color: "#4682B4" }
        ];

        // ConexÃµes do triÃ¢ngulo
        const connections = [
            { start: 0, end: 1 },
            { start: 1, end: 2 },
            { start: 2, end: 0 }
        ];

        // VariÃ¡veis de animaÃ§Ã£o
        let time = 0;
        const neuronSpeed = 0.02;
        const neuronPositions = connections.map(() => ({ t: 0, direction: 1 }));

        // FunÃ§Ã£o de animaÃ§Ã£o
        function animate() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (isProcessing) {
                time += 0.05;
                connections.forEach((connection, index) => {
                    const startNode = nodes[connection.start];
                    const endNode = nodes[connection.end];
                    const pos = neuronPositions[index];
                    pos.t += neuronSpeed * pos.direction;
                    if (pos.t >= 1) { pos.t = 1; pos.direction = -1; }
                    else if (pos.t <= 0) { pos.t = 0; pos.direction = 1; }
                    const x = startNode.x + (endNode.x - startNode.x) * pos.t;
                    const y = startNode.y + (endNode.y - startNode.y) * pos.t;
                    ctx.beginPath();
                    ctx.arc(x, y, 2, 0, Math.PI * 2);
                    ctx.fillStyle = "#ffffff";
                    ctx.fill();
                });
                nodes.forEach((node, index) => {
                    const pulse = Math.sin(time + index) * 1 + 5;
                    ctx.beginPath();
                    ctx.arc(node.x, node.y, pulse, 0, Math.PI * 2);
                    ctx.fillStyle = node.color;
                    ctx.fill();
                });
            }
            requestAnimationFrame(animate);
        }

        animate();

        // Iniciar reconhecimento contÃ­nuo
        function startContinuousRecognition() {
            const audioConfig = AudioConfig.fromDefaultMicrophoneInput();
            recognizer = new SpeechRecognizer(speechConfig, audioConfig);
            micButton.classList.add("listening");

            // Verificar acesso ao microfone
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(() => {
                    // Microfone ativo, esconder lembrete
                    micReminder.style.display = "none";
                    recognizer.recognized = (s, e) => {
                        if (e.result.reason === SpeechSDK.ResultReason.RecognizedSpeech && !isProcessing) {
                            isProcessing = true;
                            processInput(e.result.text);
                        }
                    };
                    recognizer.canceled = (s, e) => {
                        console.error("Reconhecimento cancelado:", e.errorDetails);
                        micReminder.style.display = "block"; // Mostra lembrete se falhar
                        restartRecognition();
                    };
                    recognizer.sessionStopped = () => {
                        restartRecognition();
                    };
                    recognizer.startContinuousRecognitionAsync(
                        () => console.log("Reconhecimento iniciado"),
                        (error) => {
                            console.error("Erro ao iniciar:", error);
                            micReminder.style.display = "block"; // Mostra lembrete se erro
                        }
                    );
                })
                .catch((error) => {
                    console.error("Microfone nÃ£o disponÃ­vel:", error);
                    micReminder.style.display = "block"; // Mostra lembrete se microfone nÃ£o estiver ativo
                });
        }

        // Reiniciar reconhecimento
        function restartRecognition() {
            if (recognizer) {
                recognizer.stopContinuousRecognitionAsync(
                    () => {
                        recognizer.close();
                        recognizer = null;
                        startContinuousRecognition();
                    },
                    (error) => console.error("Erro ao parar:", error)
                );
            }
        }

        // Processar entrada com Azure OpenAI
        async function processInput(input) {
            const apiKey = "SUA_CHAVE_OPENAI_AZURE";
            const endpoint = "SEU_ENDPOINT_OPENAI";
            const deployment = "SEU_DEPLOYMENT_NAME";
            const url = `${endpoint}/openai/deployments/${deployment}/chat/completions?api-version=2023-05-15`;

            try {
                const response = await fetch(url, {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        "api-key": apiKey
                    },
                    body: JSON.stringify({
                        messages: [
                            { role: "system", content: "VocÃª Ã© um assistente Ãºtil." },
                            { role: "user", content: input }
                        ],
                        max_tokens: 150,
                        temperature: 0.7
                    })
                });
                if (!response.ok) throw new Error("Erro na resposta da API");
                const data = await response.json();
                const aiResponse = data.choices[0].message.content.trim();
                speakResponse(aiResponse);
            } catch (error) {
                console.error(error);
                speakResponse("Desculpe, houve um erro ao processar sua solicitaÃ§Ã£o.");
            }
        }

        // Falar resposta com ElevenLabs
        async function speakResponse(text) {
            const elevenLabsApiKey = "SUA_CHAVE_ELEVENLABS";
            const voiceId = "SEU_VOICE_ID";
            const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`;

            try {
                const response = await fetch(url, {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        "xi-api-key": elevenLabsApiKey
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: "eleven_multilingual_v2",
                        voice_settings: { stability: 0.5, similarity_boost: 0.5 }
                    })
                });
                if (!response.ok) throw new Error("Erro na resposta do ElevenLabs");
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                audio.play();
                audio.onplay = () => {
                    isProcessing = false;
                };
            } catch (error) {
                console.error(error);
                isProcessing = false;
            }
        }

        // Iniciar ao carregar
        window.onload = () => {
            startContinuousRecognition();
        };
    </script>
</body>
</html>